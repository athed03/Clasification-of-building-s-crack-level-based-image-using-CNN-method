{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils.paths as path\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import sklearn as sk\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jumClass = 3\n",
    "kernelSize = 3\n",
    "filterConv1 = 32\n",
    "filterConv2 = 32\n",
    "neuronFLC1 = 96\n",
    "neuronFLC2 = 96\n",
    "# neuronFLC3 = 64\n",
    "size = 32\n",
    "skenario = 0.1\n",
    "channel = 3\n",
    "# nama='f10gray.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'augmentasi82'\n",
    "imagePaths = sorted(list(path.list_images(PATH)))\n",
    "random.seed(2)\n",
    "random.shuffle(imagePaths)\n",
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "# imagePaths\n",
    "# a=cv2.imread('dataset334/berat/data1-001.jpg')\n",
    "# a=cv2.resize(a,(34,34))\n",
    "# len(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asda = time.time()\n",
    "\n",
    "for i in imagePaths:\n",
    "    img = cv2.imread(i)\n",
    "#     plt.imshow(img)\n",
    "    imageScale = cv2.resize(img,(size,size))\n",
    "    imageScale = imageScale/255\n",
    "#     imageScale = sess.run(tf.image.rgb_to_grayscale(imageScale))\n",
    "    data.append(imageScale)\n",
    "    label = i.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "print(time.time()-asda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = 'dataset/train'\n",
    "# imagePaths = sorted(list(path.list_images(PATH)))\n",
    "# random.seed(2)\n",
    "# random.shuffle(imagePaths)\n",
    "# xTrain = []\n",
    "# yTrainCls = []\n",
    "# asda = time.time()\n",
    "# for i in imagePaths:\n",
    "#     img = cv2.imread(i)\n",
    "#     imageScale = cv2.resize(img,(size,size))\n",
    "#     imageScale = imageScale/255\n",
    "# #     imageScale = cv2.cvtColor(imageScale, cv2.COLOR_BGR2GRAY)\n",
    "# #     imageScale = sess.run(tf.image.rgb_to_grayscale(imageScale))\n",
    "#     xTrain.append(imageScale)\n",
    "#     label = i.split(os.path.sep)[-2]\n",
    "#     yTrainCls.append(label)\n",
    "# print(time.time()-asda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = 'dataset/testing'\n",
    "# imagePaths = sorted(list(path.list_images(PATH)))\n",
    "# random.seed(2)\n",
    "# random.shuffle(imagePaths)\n",
    "# xTest = []\n",
    "# yTestCls = []\n",
    "# asda = time.time()\n",
    "# for i in imagePaths:\n",
    "#     img = cv2.imread(i)\n",
    "#     imageScale = cv2.resize(img,(size,size))\n",
    "#     imageScale = imageScale/255\n",
    "# #     imageScale = cv2.cvtColor(imageScale, cv2.COLOR_BGR2GRAY)\n",
    "# #     imageScale = sess.run(tf.image.rgb_to_grayscale(imageScale))\n",
    "#     xTest.append(imageScale)\n",
    "#     label = i.split(os.path.sep)[-2]\n",
    "#     yTestCls.append(label)\n",
    "# print(time.time()-asda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = np.array(data)\n",
    "lbl = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xTrain = np.asarray(xTrain)\n",
    "# yTestCls = np.asarray(yTestCls)\n",
    "# yTrainCls = np.asarray(yTrainCls)\n",
    "# xTest = np.asarray(xTest)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrainCls, yTestCls = train_test_split(dt, lbl, test_size=skenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(yTrainCls),len(yTestCls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(yTrainCls)\n",
    "y = encoder.transform(yTrainCls)\n",
    "yTrain = one_hot_encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(yTestCls)\n",
    "y = encoder.transform(yTestCls)\n",
    "yTest = one_hot_encode(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype = tf.float32, shape=[None,size,size,channel], name='x')\n",
    "# xImage = tf.reshape(x, shape=[-1,size,size,3])\n",
    "# keepProb = tf.placeholder(dtype=tf.float32, name='keepProb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerKonvolusi(masukan, kernel, filterConv):\n",
    "    weight = tf.Variable(tf.truncated_normal(kernel,stddev=0.05))\n",
    "    konvolusi = tf.nn.conv2d(masukan, weight, strides=[1,1,1,1], padding='SAME')\n",
    "    active = tf.nn.relu(konvolusi)\n",
    "#     minimal = tf.math.reduce_min(konvolusi)\n",
    "#     maximal = tf.math.reduce_max(konvolusi)\n",
    "#     s1 = konvolusi-minimal\n",
    "#     s2 = maximal-minimal\n",
    "#     active = s1/s2\n",
    "#     print(active)\n",
    "    maxpool = tf.nn.max_pool(active, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    return maxpool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outConv1 = layerKonvolusi(x, kernel=[kernelSize,kernelSize,channel, filterConv1], filterConv=filterConv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outConv2 = layerKonvolusi(outConv1, kernel=[kernelSize,kernelSize,filterConv1,filterConv2], filterConv=filterConv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerNN(masukan, nInput, nOutput, dropRelu):\n",
    "    weight = tf.Variable(tf.truncated_normal(shape=[nInput,nOutput], stddev=0.05))\n",
    "    bias = tf.Variable(tf.constant(1.0,shape=[nOutput]))\n",
    "    fcl = tf.matmul(masukan, weight)\n",
    "    out = fcl+bias\n",
    "    \n",
    "    if dropRelu:\n",
    "        out = tf.nn.relu(out)\n",
    "        out = tf.nn.dropout(out,0.2)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexFlat = math.ceil(size/4)\n",
    "outFlat = tf.reshape(outConv2, shape=[-1, indexFlat*indexFlat*filterConv2])\n",
    "outHL1 = layerNN(outFlat, indexFlat*indexFlat*filterConv2, neuronFLC1, True)\n",
    "outHL2 = layerNN(outHL1, neuronFLC1, neuronFLC2, True)\n",
    "# outHL3 = layerNN(outHL2, neuronFLC2, neuronFLC3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = layerNN(outHL2, neuronFLC2, jumClass, False)\n",
    "\n",
    "yPred = tf.nn.softmax(y, name='yPred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32,shape=[None,jumClass], name='y_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPredArg = tf.argmax(yPred, dimension=1)\n",
    "y_Arg = tf.argmax(y_, dimension=1)\n",
    "yArg = tf.argmax(y, dimension=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y,labels=y_))\n",
    "correctPrediction = tf.equal(yPredArg, y_Arg)\n",
    "accuracyPrediction = tf.reduce_mean(tf.cast(correctPrediction,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPreda = []\n",
    "ya = []\n",
    "y_a = []\n",
    "fitur = []\n",
    "lab = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for i in range(100):\n",
    "    for k in range(math.ceil(len(xTrain)/20)):\n",
    "        xBatch = xTrain[k*20:min((k+1)*20,len(xTrain))]\n",
    "        yBatch = yTrain[k*20:min((k+1)*20,len(yTrain))]\n",
    "#         print(yTrain[1])\n",
    "        sess.run(optimizer, feed_dict={\n",
    "            x:xBatch,\n",
    "            y_:yBatch\n",
    "#             keepProb:0.2\n",
    "        })\n",
    "    \n",
    "        flat,labelnya, loss, acc= sess.run([outFlat,y_, cost,accuracyPrediction], feed_dict={\n",
    "            x:xBatch,\n",
    "            y_:yBatch\n",
    "#             keepProb:0.2\n",
    "        })\n",
    "        \n",
    "#         if(i==99):\n",
    "#             fitur.append(flat)\n",
    "#             lab.append(labelnya)\n",
    "            \n",
    "    tesAcc, tesLoss, tesY, labelY, softY = sess.run([accuracyPrediction,cost, yArg, y_Arg, yPredArg], feed_dict={\n",
    "        x:xTest,\n",
    "        y_:yTest\n",
    "#         keepProb:0.2\n",
    "    })\n",
    "    \n",
    "    print(\"Iter \" + str(i) + \", Loss= \" + \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \"{:.5f}\".format(acc) +\n",
    "         \", Loss Test \" + \"{:.6f}\".format(tesLoss) + \", Accuration Test \" + \"{:.5f}\".format(tesAcc))\n",
    "    \n",
    "    saver.save(sess, \"/home/athed/Dropbox/skripsi/project/model/fix\")\n",
    "print(time.time()-start,\"s\")\n",
    "ya=tesY\n",
    "y_a=labelY\n",
    "yPreda=softY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saver.save(sess, \"/home/athed/Dropbox/skripsi/project/model/fix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppp= sess.run(tf.confusion_matrix(labels=y_a,predictions=yPreda,num_classes=3, name='s'))\n",
    "print(ppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9998128e-01 4.1043520e-09 1.8657012e-05]]\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "img = cv2.imread(\"/home/athed/Dropbox/skripsi/project/augmentasi82/berat/data1-001.jpg\")\n",
    "#     plt.imshow(img)\n",
    "imageScale = cv2.resize(img,(32,32))\n",
    "imageScale = imageScale/255\n",
    "#     imageScale = sess.run(tf.image.rgb_to_grayscale(imageScale))\n",
    "data.append(imageScale)\n",
    "print(sess.run(yPred,feed_dict={\n",
    "    x:data\n",
    "#     keepProb:0.2\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/athed/Dropbox/skripsi/project/model/fix\n",
      "[[9.9977392e-01 1.2708865e-07 2.2592797e-04]]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.import_meta_graph('model/fix.meta')\n",
    "saver.restore(sess, tf.train.latest_checkpoint('model/'))\n",
    "graph = tf.get_default_graph()\n",
    "p= graph.get_tensor_by_name(\"x:0\") \n",
    "yPreda = graph.get_tensor_by_name(\"yPred:0\")\n",
    "aa=sess.run(yPreda,feed_dict={\n",
    "    p:data\n",
    "#     keepProb:0.2\n",
    "})\n",
    "print(aa)\n",
    "print(np.argmax(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "# print(sess.run(yPredArg, feed_dict={\n",
    "#     x:xTest,\n",
    "#     keepProb:0.2\n",
    "# }))\n",
    "# print(yTestCls)\n",
    "xBatch = xTrain[a:(a+1)]\n",
    "kelas = yTestCls[a:(a+1)]\n",
    "gambar = xTest[a:(a+1)]\n",
    "\n",
    "# print(sess.run(y, feed_dict={\n",
    "#     x:xBatch,\n",
    "#     keepProb:0.2\n",
    "# }))\n",
    "# aya= sess.run(yPred, feed_dict={\n",
    "#     x:xBatch,\n",
    "#     keepProb:0.2\n",
    "# })\n",
    "# print(aya,np.argmax(aya))\n",
    "print(sess.run(y,feed_dict={\n",
    "    x:xBatch,\n",
    "    keepProb:0.2\n",
    "}))\n",
    "# plt.title(kelas[0])\n",
    "# plt.imshow(gambar[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_graph = my_graph = tf.get_default_graph()\n",
    "tf.train.write_graph(my_graph,\"/home/athed/Dropbox/skripsi/project/model\",\n",
    "                     '/model/saved_model.pb', as_text=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_a=np.asarray(y_a)\n",
    "# print(y_a)\n",
    "# y_aa = [2,2,2,1,0,1,1,1,0]\n",
    "# print(type(y_aa))\n",
    "# labelnya = np.asarray(labelnya)\n",
    "# labelnya.shape\n",
    "# np.savetxt('a.txt',flat, fmt=\"%7.3f\")\n",
    "# aaa = sess.run(y_Arg, feed_dict={\n",
    "#     y_:yTest\n",
    "# })\n",
    "fitur = sess.run(outFlat, feed_dict={\n",
    "    x:xTest,\n",
    "    y:yTest,\n",
    "    keepProb:0.2\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitur = np.asarray(fitur)\n",
    "fitur.shape\n",
    "# print(fitur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnn = len(yTestCls)\n",
    "len(yTestCls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsn=[]\n",
    "berat=[]\n",
    "nn=[]\n",
    "nama = \"sedang\"\n",
    "for i in range (2048):\n",
    "    x=0\n",
    "    clsn = 0\n",
    "#     for j in range (20):\n",
    "    for k in range(nnn):\n",
    "        if yTestCls[k] == nama:\n",
    "            x = x + fitur[k,i]\n",
    "            clsn = clsn + 1 \n",
    "    nn.append(x)    \n",
    "    n=\"gempa-fitur-\"+nama+\".xls\"\n",
    "    np.savetxt(n,nn,fmt=\"%.3f\")\n",
    "print(clsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsn=[]\n",
    "berat=[]\n",
    "nn=[]\n",
    "nama = \"ringan\"\n",
    "for i in range (2048):\n",
    "    x=0\n",
    "    clsn = 0\n",
    "#     for j in range (20):\n",
    "    for k in range(nnn):\n",
    "        if yTestCls[k] == nama:\n",
    "            x = x + fitur[k,i]\n",
    "            clsn = clsn + 1 \n",
    "    nn.append(x)    \n",
    "    n=\"gempa-fitur-\"+nama+\".xls\"\n",
    "    np.savetxt(n,nn,fmt=\"%.3f\")\n",
    "print(clsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsn=[]\n",
    "berat=[]\n",
    "nn=[]\n",
    "nama = \"berat\"\n",
    "for i in range (2048):\n",
    "    x=0\n",
    "    clsn = 0\n",
    "#     for j in range (20):\n",
    "    for k in range(nnn):\n",
    "        if yTestCls[k] == nama:\n",
    "            x = x + fitur[k,i]\n",
    "            clsn = clsn + 1 \n",
    "    nn.append(x)    \n",
    "    n=\"gempa-fitur-\"+nama+\".xls\"\n",
    "    np.savetxt(n,nn,fmt=\"%.3f\")\n",
    "print(clsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = np.asarray(nn)\n",
    "nn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fitur\n",
    "data.shape\n",
    "# print(data[1,:,:])\n",
    "for i in range(42):\n",
    "    n=\"fitur/fitur\"+str(i)+\".xls\"\n",
    "    np.savetxt(n,data[i,:,:],fmt=\"%.3f\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Write the array to disk\n",
    "with open('test.txt', 'w') as outfile:\n",
    "    # I'm writing a header here just for the sake of readability\n",
    "    # Any line starting with \"#\" will be ignored by numpy.loadtxt\n",
    "    outfile.write('# Array shape: {0}\\n'.format(data.shape))\n",
    "\n",
    "    # Iterating through a ndimensional array produces slices along\n",
    "    # the last axis. This is equivalent to data[i,:,:] in this case\n",
    "    for data_slice in data:\n",
    "\n",
    "        # The formatting string indicates that I'm writing out\n",
    "        # the values in left-justified columns 7 characters in width\n",
    "        # with 2 decimal places.  \n",
    "        np.savetxt(outfile, data_slice, fmt='%-7.2f')\n",
    "\n",
    "        # Writing out a break to indicate different slices...\n",
    "        outfile.write('# New slice\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ntp\\n\" , nTP, \"stp\\n\",st)\n",
    "# yPreda = np.asarray(yPreda)\n",
    "# print(yPreda)\n",
    "# nn=sess.run(tf.reshape(yPreda,[1]))\n",
    "# ppp= sess.run(tf.confusion_m?matrix(labels=y_a,predictions=yPreda,num_classes=2, name='s')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.imshow(ppp, interpolation='nearest', cmap=None)\n",
    "# plt.title(\"title\")\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(yTestCls))\n",
    "# nn = np.array(ya.tolist())\n",
    "# print(type(y_a))\n",
    "# np.sum(ppp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aaa=np.trace(ppp)/np.sum(ppp)\n",
    "# aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=[[10,2,3],[4,5,6]]\n",
    "d=np.asarray(d)\n",
    "d-=9\n",
    "a=tf.nn.relu(d)\n",
    "print(a)\n",
    "print((sess.run(tf.nn.relu(d))))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mina = sess.run(tf.math.reduce_min(d))\n",
    "print(mina)\n",
    "maxa = sess.run(tf.math.reduce_max(d))\n",
    "print(maxa)\n",
    "print(maxa-mina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.divide((d-mina),(maxa-mina)))\n",
    "dm = d-mina\n",
    "print(\"\")\n",
    "print(dm)\n",
    "mm = maxa-mina\n",
    "print(\"\")\n",
    "print(dm/mm)\n",
    "\n",
    "# print((k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.divide(d,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
